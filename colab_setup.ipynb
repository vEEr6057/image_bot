{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s-yAzHqeoS9"
      },
      "source": [
        "#  Telegram Image Upscaling Bot - Google Colab GPU\n",
        "\n",
        "**Speed**: 5-10 seconds instead of 8-9 minutes (100 faster!)\n",
        "\n",
        "## Quick Start:\n",
        "1. Runtime > Change runtime type > T4 GPU\n",
        "2. Run all cells in order\n",
        "3. Keep this tab open while using the bot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw2iJyjCeoS-"
      },
      "source": [
        "## Step 1: Check GPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YH0snohdeoS-",
        "outputId": "0f976491-69ec-43df-d6be-75548f5f02ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch: 2.8.0+cu126\n",
            "CUDA: True\n",
            "GPU: Tesla T4\n",
            "Memory: 14.74 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
        "else:\n",
        "    print(\" No GPU! Go to Runtime > Change runtime type > T4 GPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOJ40l6meoS_"
      },
      "source": [
        "## Step 2: Clone Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3rQPfDvceoS_",
        "outputId": "a5f8a1ac-96d6-47fa-be17-45195de3393a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'image_bot'...\n",
            "remote: Enumerating objects: 43, done.\u001b[K\n",
            "remote: Counting objects: 100% (43/43), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 43 (delta 14), reused 37 (delta 8), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (43/43), 32.58 KiB | 16.29 MiB/s, done.\n",
            "Resolving deltas: 100% (14/14), done.\n",
            "/content/image_bot\n",
            "total 68\n",
            "drwxr-xr-x 5 root root 4096 Nov 17 11:02 .\n",
            "drwxr-xr-x 1 root root 4096 Nov 17 11:02 ..\n",
            "-rw-r--r-- 1 root root 3189 Nov 17 11:02 COLAB_GUIDE.md\n",
            "-rw-r--r-- 1 root root 3950 Nov 17 11:02 colab_setup.ipynb\n",
            "-rw-r--r-- 1 root root  306 Nov 17 11:02 .env.example\n",
            "drwxr-xr-x 8 root root 4096 Nov 17 11:02 .git\n",
            "-rw-r--r-- 1 root root  173 Nov 17 11:02 .gitignore\n",
            "-rw-r--r-- 1 root root  113 Nov 17 11:02 main.py\n",
            "-rw-r--r-- 1 root root 1526 Nov 17 11:02 QUICKSTART.md\n",
            "-rw-r--r-- 1 root root 7493 Nov 17 11:02 README.md\n",
            "-rw-r--r-- 1 root root  319 Nov 17 11:02 requirements-colab.txt\n",
            "-rw-r--r-- 1 root root  213 Nov 17 11:02 requirements.txt\n",
            "drwxr-xr-x 2 root root 4096 Nov 17 11:02 src\n",
            "drwxr-xr-x 2 root root 4096 Nov 17 11:02 temp\n",
            "-rw-r--r-- 1 root root 5957 Nov 17 11:02 USER_GUIDE.md\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/vEEr6057/image_bot.git\n",
        "%cd image_bot\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsYjYvOseoS_"
      },
      "source": [
        "## Step 3: Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "t3ivpffWeoS_",
        "outputId": "8d282d5b-c1a2-40a8-c426-790814cd463b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/604.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m604.2/604.9 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m604.9/604.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-genai 1.49.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.26.0 which is incompatible.\n",
            "mcp 1.21.0 requires httpx>=0.27.1, but you have httpx 0.26.0 which is incompatible.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mcp 1.21.0 requires httpx>=0.27.1, but you have httpx 0.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "google-genai 1.49.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.26.0 which is incompatible.\n",
            "gradio 5.49.1 requires pillow<12.0,>=8.0, but you have pillow 12.0.0 which is incompatible.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.3/64.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h Installed! (Ignore warnings)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade python-telegram-bot==20.8\n",
        "!pip install -q python-dotenv==1.0.0\n",
        "!pip install -q --upgrade opencv-python-headless>=4.9.0.80\n",
        "!pip install -q --upgrade Pillow requests\n",
        "!pip install -q apscheduler==3.11.1\n",
        "print(\" Installed! (Ignore warnings)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veGVG_ioeoTA"
      },
      "source": [
        "## Step 4: Configure Bot Credentials\n",
        "\n",
        "Uncomment and fill in your bot token and user ID:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fetG0z9aeoTA",
        "outputId": "8d545f2e-b871-48c7-d17f-5b3a5f5f3555",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Bot configured!\n",
            "Bot Token: 8234724646:AAFB-FZjL...\n",
            "Admin ID: 1412431165\n"
          ]
        }
      ],
      "source": [
        "# Uncomment and fill in:\n",
        "BOT_TOKEN = \"8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU\"\n",
        "ADMIN_USER_ID = \"1412431165\"\n",
        "\n",
        "# Create .env file\n",
        "with open('.env', 'w') as f:\n",
        "    f.write(f\"BOT_TOKEN={BOT_TOKEN}\\n\")\n",
        "    f.write(f\"ADMIN_IDS={ADMIN_USER_ID}\\n\")\n",
        "    f.write(\"USE_GPU=true\\n\")\n",
        "\n",
        "print(\" Bot configured!\")\n",
        "print(f\"Bot Token: {BOT_TOKEN[:20]}...\")\n",
        "print(f\"Admin ID: {ADMIN_USER_ID}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eww1ldfeoTA"
      },
      "source": [
        "## Step 5: Start Bot\n",
        "\n",
        "**Keep this cell running!** Bot stays online while executing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "im24uadgeoTA",
        "outputId": "04cc4c26-1185-48fc-fcfd-124b261dc4f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Starting bot on GPU...\n",
            "\n",
            "2025-11-17 11:05:43,090 - src.bot - INFO - Loading super-resolution model...\n",
            "Model not found at /content/image_bot/weights/RealESRGAN_x4plus.pth\n",
            "Downloading model... (this may take a while)\n",
            "Downloading from https://github.com/xinntao/Real-ESRGAN/releases/download/v0.1.0/RealESRGAN_x4plus.pth\n",
            "This may take several minutes (~65 MB)...\n",
            "Downloading: 100.0% (63.9 MB / 63.9 MB)\n",
            "Model downloaded successfully to /content/image_bot/weights/RealESRGAN_x4plus.pth\n",
            "Loading model from /content/image_bot/weights/RealESRGAN_x4plus.pth\n",
            "Model loaded: RealESRGAN_x4plus on cuda\n",
            "2025-11-17 11:05:45,928 - src.bot - INFO - Model loaded successfully!\n",
            "2025-11-17 11:05:46,026 - src.bot - INFO - Starting bot...\n",
            "2025-11-17 11:05:46,614 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getMe \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:05:46,763 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/deleteWebhook \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:05:46,764 - telegram.ext.Application - INFO - Application started\n",
            "2025-11-17 11:05:57,214 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:06:05,780 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:06:06,449 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/sendMessage \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:06:15,933 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:06:21,107 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:06:21,109 - src.bot - INFO - Photo received from user 1412431165\n",
            "2025-11-17 11:06:21,797 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/sendMessage \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:06:21,946 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getFile \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:06:22,242 - httpx - INFO - HTTP Request: GET https://api.telegram.org/file/bot8234724646%3AAAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/photos/file_0.jpg \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:06:22,857 - src.bot - INFO - Processing image for user 1412431165: f891b6c9d03a4331a7113cd30f7d5d38.png\n",
            "2025-11-17 11:06:23,223 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/editMessageText \"HTTP/1.1 200 OK\"\n",
            "Image too large (15.8 MB), compressing to under 9.5 MB...\n",
            "Reduced quality to 85, size: 15.3 MB\n",
            "Reduced quality to 75, size: 14.8 MB\n",
            "Reduced quality to 65, size: 14.6 MB\n",
            "Reduced quality to 55, size: 14.6 MB\n",
            "Reduced quality to 45, size: 14.2 MB\n",
            "Reduced quality to 35, size: 13.8 MB\n",
            "Resized to 2592×4608, size: 11.3 MB\n",
            "Resized to 2332×4147, size: 8.8 MB\n",
            "Final size: 8.8 MB\n",
            "2025-11-17 11:06:51,606 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:06:52,246 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/editMessageText \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:06:56,515 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/sendPhoto \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:06:56,840 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/deleteMessage \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:06:56,840 - src.bot - INFO - Successfully processed image for user 1412431165\n",
            "2025-11-17 11:07:01,757 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:07:06,890 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:07:07,526 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/sendMessage \"HTTP/1.1 200 OK\"\n",
            "Image too large (9.8 MB), compressing to under 9.5 MB...\n",
            "Reduced quality to 85, size: 9.5 MB\n",
            "Final size: 9.5 MB\n",
            "2025-11-17 11:07:10,812 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/editMessageText \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:07:14,139 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/sendPhoto \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:07:14,464 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/deleteMessage \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:07:14,467 - src.bot - INFO - Applied preset 'cinematic' for user 1412431165\n",
            "2025-11-17 11:07:17,043 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:07:27,195 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:07:37,346 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:07:47,498 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:07:57,662 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:08:07,813 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:08:17,967 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:08:28,119 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:08:38,271 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:08:48,421 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:08:58,572 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:09:08,724 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:09:11,921 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:09:12,604 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/sendMessage \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:09:22,073 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n",
            "2025-11-17 11:09:32,224 - httpx - INFO - HTTP Request: POST https://api.telegram.org/bot8234724646:AAFB-FZjLabVQ7iDhz_viQ8cL5V5ahP2qoU/getUpdates \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "print(\" Starting bot on GPU...\\n\")\n",
        "!python main.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv98VtBNeoTB"
      },
      "source": [
        "##  Tips:\n",
        "\n",
        "- **Keep tab open**: Bot runs while this cell executes\n",
        "- **Free tier limits**: 12 hours max, 90 min idle timeout\n",
        "- **Reconnect**: Just re-run the last cell\n",
        "- **24/7 operation**: Upgrade to Colab Pro ($10/month)\n",
        "\n",
        "##  Troubleshooting:\n",
        "\n",
        "- **No GPU detected?** Runtime > Change runtime type > T4 GPU\n",
        "- **Bot not responding?** Check if last cell shows [*]\n",
        "- **Dependency conflicts?** Ignore warnings - they're harmless\n",
        "- **Out of memory?** Shouldn't happen with T4 GPU (16GB)\n",
        "\n",
        "##  Next Steps:\n",
        "\n",
        "1. Send an image to your bot on Telegram\n",
        "2. Watch it process in ~5-10 seconds!\n",
        "3. Try color grading presets: /presets\n",
        "\n",
        "Enjoy your 100 speed boost!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}