{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bf8013d",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0da8b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if GPU is available\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸ WARNING: GPU not detected! Make sure Runtime > Change runtime type > GPU is selected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df42a71",
   "metadata": {},
   "source": [
    "## Step 2: Clone Your Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb8d5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your bot repository from GitHub\n",
    "!git clone https://github.com/vEEr6057/TEST.git\n",
    "%cd TEST/image_bot\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5425844e",
   "metadata": {},
   "source": [
    "## Step 3: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f49ccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q python-telegram-bot==20.8\n",
    "!pip install -q python-dotenv==1.0.0\n",
    "!pip install -q opencv-python-headless==4.8.1.78\n",
    "!pip install -q Pillow==10.1.0\n",
    "!pip install -q requests==2.31.0\n",
    "!pip install -q apscheduler==3.11.1\n",
    "\n",
    "# PyTorch should already be installed with CUDA on Colab\n",
    "print(\"âœ… Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99c4e4e",
   "metadata": {},
   "source": [
    "## Step 4: Configure Environment Variables\n",
    "\n",
    "**Option A**: Upload your `.env` file using the file browser on the left  \n",
    "**Option B**: Enter credentials manually below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37e3ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option B: Manual configuration (if you didn't upload .env file)\n",
    "# Uncomment and fill in your credentials:\n",
    "\n",
    "# BOT_TOKEN = \"your_bot_token_here\"\n",
    "# ADMIN_USER_ID = \"your_telegram_user_id_here\"\n",
    "\n",
    "# # Write .env file\n",
    "# with open('.env', 'w') as f:\n",
    "#     f.write(f\"BOT_TOKEN={BOT_TOKEN}\\n\")\n",
    "#     f.write(f\"ADMIN_USER_ID={ADMIN_USER_ID}\\n\")\n",
    "#     f.write(\"USE_GPU=true\\n\")  # Enable GPU!\n",
    "\n",
    "# Check if .env exists\n",
    "import os\n",
    "if os.path.exists('.env'):\n",
    "    print(\"âœ… .env file found!\")\n",
    "    # Add GPU flag if not present\n",
    "    with open('.env', 'r') as f:\n",
    "        content = f.read()\n",
    "    if 'USE_GPU' not in content:\n",
    "        with open('.env', 'a') as f:\n",
    "            f.write('\\nUSE_GPU=true\\n')\n",
    "        print(\"âœ… GPU flag added to .env\")\n",
    "else:\n",
    "    print(\"âŒ .env file not found! Please upload it or configure manually above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9734bac2",
   "metadata": {},
   "source": [
    "## Step 5: Update Config to Use GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa95c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU will be used\n",
    "from src.config import Config\n",
    "print(f\"Device: {Config.DEVICE}\")\n",
    "if Config.DEVICE == 'cpu':\n",
    "    print(\"âš ï¸ WARNING: Still using CPU! Check GPU availability above.\")\n",
    "else:\n",
    "    print(\"âœ… GPU will be used for processing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fd2890",
   "metadata": {},
   "source": [
    "## Step 6: Start the Bot\n",
    "\n",
    "**Keep this cell running!** The bot will stay online as long as this cell is executing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ad33bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the bot\n",
    "print(\"ðŸš€ Starting bot on GPU...\\n\")\n",
    "!python main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc1c928",
   "metadata": {},
   "source": [
    "## Tips:\n",
    "\n",
    "- **Keep this tab open** while using the bot\n",
    "- Colab free tier disconnects after ~12 hours or 90 minutes of inactivity\n",
    "- For 24/7 operation, use Colab Pro ($10/month) or deploy to a cloud service\n",
    "- Processing should now take 5-10 seconds instead of 8-9 minutes!\n",
    "\n",
    "## Troubleshooting:\n",
    "\n",
    "- **No GPU detected?** Go to `Runtime > Change runtime type > Hardware accelerator > GPU`\n",
    "- **Bot not responding?** Check if the cell above is still running (shows [*] next to it)\n",
    "- **Out of memory?** Reduce tile size in `src/config.py`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
